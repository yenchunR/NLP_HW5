{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLZ/t1Ta7UB9knldfJBFhl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yenchunR/NLP_HW5/blob/master/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SQRoPRi184S"
      },
      "source": [
        "# Import module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb3qOs32gUAW"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from IPython.display import clear_output "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0gW8GfA5r1v"
      },
      "source": [
        "!pip3 uninstall tensorflow-gpu==2.0.0-beta0\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 uninstall keras\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwMdBxPM4AsD"
      },
      "source": [
        "!pip3 uninstall tensorflow-gpu==2.0.0-beta0\n",
        "!pip3 install tensorflow-gpu==2.0.0-beta0\n",
        "!pip3 uninstall tensorflow\n",
        "!pip3 install tensorflow\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwwtxGvN-NeQ"
      },
      "source": [
        "!pip3 uninstall tensorflow-datasets\n",
        "!pip3 install tensorflow-datasets\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2HZO9efBga7"
      },
      "source": [
        "!pip3 install --ignore-installed --upgrade --ignore-installed tensorflow\n",
        "clear_output()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSl4h07hBLxs",
        "outputId": "6a8dd199-ac7b-4f67-9e1b-d4aa3e86dc89"
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "clear_output()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wkTG5C34G60"
      },
      "source": [
        "## 改變 logging 等級"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFnj0994KEz"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=\"ERROR\")\n",
        "\n",
        "np.set_printoptions(suppress=True) #讓 numpy 不要顯示科學記號"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tykotz1DBqA"
      },
      "source": [
        "# 路徑變數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP5hwEf1DDOb"
      },
      "source": [
        "output_dir = \"nmt\"\n",
        "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
        "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(output_dir, 'logs')\n",
        "download_dir = \"tensorflow-datasets/downloads\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCZeifuPDbbh"
      },
      "source": [
        "# 建立輸入管道"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxquHFw0Dcd8"
      },
      "source": [
        "## 下載並準備資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WfNNuu4DfCs",
        "outputId": "2d579f1f-010e-4d00-c5a9-244f51193196"
      },
      "source": [
        "tmp_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
        "pprint(tmp_builder.subsets)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{Split('train'): ['newscommentary_v14',\n",
            "                  'wikititles_v1',\n",
            "                  'uncorpus_v1',\n",
            "                  'casia2015',\n",
            "                  'casict2011',\n",
            "                  'casict2015',\n",
            "                  'datum2015',\n",
            "                  'datum2017',\n",
            "                  'neu2017'],\n",
            " Split('validation'): ['newstest2018']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fn3wHgiDmX4"
      },
      "source": [
        "## Download News Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNq-PPj4DqWO"
      },
      "source": [
        "config = tfds.translate.wmt.WmtConfig(\n",
        "    version=\"0.0.3\",\n",
        "    language_pair=(\"zh\", \"en\"),\n",
        "    subsets={\n",
        "        tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
        "    },\n",
        ")\n",
        "builder = tfds.builder(\"wmt_translate\", config=config)\n",
        "builder.download_and_prepare(download_dir=download_dir)\n",
        "clear_output()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vil8PpmWHJko"
      },
      "source": [
        "## 切割資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIYsVYZLHK4y",
        "outputId": "feccbdf2-2fff-4213-d39b-43f44c388b56"
      },
      "source": [
        "examples = builder.as_dataset(split=['train[:20%]','train[20%:21%]','train[21%:]'], as_supervised=True)\n",
        "\n",
        "train_examples, val_examples, _ = examples\n",
        "print(train_examples)\n",
        "print(val_examples)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n",
            "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCKhnpIFJyAR"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX9XwhHlJ2Nn",
        "outputId": "48cf1126-93f1-4948-eb72-6ae98ef7d2c1"
      },
      "source": [
        "for en, zh in train_examples.take(3):\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word \\xe2\\x80\\x9cliberal\\xe2\\x80\\x9d \\xe2\\x80\\x93 a champion of the cause of individual freedom.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe4\\xba\\x8b\\xe5\\xae\\x9e\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe5\\xbe\\xb7\\xe5\\x9b\\xbd\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xb1\\x80\\xe5\\x8a\\xbf\\xe9\\x9c\\x80\\xe8\\xa6\\x81\\xe7\\x9a\\x84\\xe4\\xb8\\x8d\\xe8\\xbf\\x87\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe7\\xac\\xa6\\xe5\\x90\\x88\\xe7\\xbe\\x8e\\xe5\\x9b\\xbd\\xe6\\x89\\x80\\xe8\\xb0\\x93\\xe2\\x80\\x9c\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe2\\x80\\x9d\\xe5\\xae\\x9a\\xe4\\xb9\\x89\\xe7\\x9a\\x84\\xe7\\x9c\\x9f\\xe6\\xad\\xa3\\xe7\\x9a\\x84\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe5\\x85\\x9a\\xe6\\xb4\\xbe\\xef\\xbc\\x8c\\xe4\\xb9\\x9f\\xe5\\xb0\\xb1\\xe6\\x98\\xaf\\xe4\\xb8\\xaa\\xe4\\xba\\xba\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe4\\xba\\x8b\\xe4\\xb8\\x9a\\xe7\\x9a\\x84\\xe5\\x80\\xa1\\xe5\\xaf\\xbc\\xe8\\x80\\x85\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe5\\xbf\\x85\\xe9\\xa1\\xbb\\xe4\\xbb\\x98\\xe5\\x87\\xba\\xe5\\xb7\\xa8\\xe5\\xa4\\xa7\\xe7\\x9a\\x84\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\x92\\x8c\\xe5\\x9f\\xba\\xe7\\xa1\\x80\\xe8\\xae\\xbe\\xe6\\x96\\xbd\\xe6\\x8a\\x95\\xe8\\xb5\\x84\\xe6\\x89\\x8d\\xe8\\x83\\xbd\\xe5\\xae\\x8c\\xe6\\x88\\x90\\xe5\\x90\\x91\\xe5\\x8f\\xaf\\xe5\\x86\\x8d\\xe7\\x94\\x9f\\xe8\\x83\\xbd\\xe6\\xba\\x90\\xe7\\x9a\\x84\\xe8\\xbf\\x87\\xe6\\xb8\\xa1\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCTtEfPlJ99m"
      },
      "source": [
        "#### 利用 numpy() 取出並解碼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kilwBcHRJ_rp"
      },
      "source": [
        "sample_examples = []\n",
        "num_samples = 10\n",
        "\n",
        "for en_t, zh_t in train_examples.take(num_samples):\n",
        "  en = en_t.numpy().decode(\"utf-8\")\n",
        "  zh = zh_t.numpy().decode(\"utf-8\")\n",
        "  \n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  # 之後用來簡單評估模型的訓練情況\n",
        "  sample_examples.append((en, zh))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb9yS6YXKFsi"
      },
      "source": [
        "# 建立中文與英文字典"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y61Uw0XuKI3x"
      },
      "source": [
        "## 為英文語料建立字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqjJkMAiKKEG",
        "outputId": "fc378cad-a7a9-4222-e2c6-84939a600580"
      },
      "source": [
        "## load_from_file 函式嘗試讀取之前已經建好的字典檔案\n",
        "\n",
        "%%time\n",
        "try:\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
        "  print(f\"載入已建立的字典： {en_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (en.numpy() for en, _ in train_examples), \n",
        "      target_vocab_size=2**13) # 有需要可以調整字典大小\n",
        "  \n",
        "  # 將字典檔案存下以方便下次 warmstart\n",
        "  subword_encoder_en.save_to_file(en_vocab_file)\n",
        "  \n",
        "\n",
        "print(f\"字典大小：{subword_encoder_en.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_en.subwords[:10]}\")\n",
        "print()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "沒有已建立的字典，從頭建立。\n",
            "字典大小：8113\n",
            "前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n",
            "\n",
            "CPU times: user 1min 57s, sys: 4.07 s, total: 2min 1s\n",
            "Wall time: 2min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-b4mWqhME1H"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ywSl8pMMD-"
      },
      "source": [
        "#### 用該字典來幫我們將一個英文句子轉成對應的索引序列（index sequence）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAI941N7MNug",
        "outputId": "83c51db2-06b2-4724-b306-fc235f273237"
      },
      "source": [
        "sample_string = 'Taiwan is beautiful.'\n",
        "indices = subword_encoder_en.encode(sample_string)\n",
        "indices"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3461, 7889, 9, 3502, 4379, 1134, 7903]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYStc5OMSmB"
      },
      "source": [
        "#### 將這些索引還原"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJtUqVFtMToE",
        "outputId": "894a85b4-9909-463e-fc49-ec82c7704d37"
      },
      "source": [
        "print(\"{0:10}{1:6}\".format(\"Index\", \"Subword\"))\n",
        "print(\"-\" * 15)\n",
        "for idx in indices:\n",
        "  subword = subword_encoder_en.decode([idx])\n",
        "  print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index     Subword\n",
            "---------------\n",
            " 3461     Taiwan\n",
            " 7889      \n",
            "    9     is \n",
            " 3502     bea\n",
            " 4379     uti\n",
            " 1134     ful\n",
            " 7903     .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HWJJUP-Mc_p"
      },
      "source": [
        "#### 編碼與解碼是 2 個完全可逆"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3yxRXv_MeiH",
        "outputId": "579feb3f-c0fb-4968-e97a-1c1b2cb86376"
      },
      "source": [
        "sample_string = 'Taiwan is beautiful.'\n",
        "indices = subword_encoder_en.encode(sample_string)\n",
        "decoded_string = subword_encoder_en.decode(indices)\n",
        "assert decoded_string == sample_string\n",
        "pprint((sample_string, decoded_string))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Taiwan is beautiful.', 'Taiwan is beautiful.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgGBuP5AMlHo"
      },
      "source": [
        "## 為中文建立一個字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpTrJyz2MqYO",
        "outputId": "bcf18c2d-4548-4a1c-9014-a39817271d14"
      },
      "source": [
        "#https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder\n",
        "\n",
        "%%time\n",
        "try:\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
        "  print(f\"載入已建立的字典： {zh_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (zh.numpy() for _, zh in train_examples), \n",
        "      target_vocab_size=2**13, # 有需要可以調整字典大小\n",
        "      max_subword_length=1) # 每一個中文字就是字典裡的一個單位\n",
        "  \n",
        "  # 將字典檔案存下以方便下次 warmstart \n",
        "  subword_encoder_zh.save_to_file(zh_vocab_file)\n",
        "\n",
        "print(f\"字典大小：{subword_encoder_zh.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}\")\n",
        "print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "沒有已建立的字典，從頭建立。\n",
            "字典大小：4205\n",
            "前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n",
            "\n",
            "CPU times: user 10min 6s, sys: 3.08 s, total: 10min 9s\n",
            "Wall time: 10min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCkh5QrWPE31"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMR6lEPfPHKp"
      },
      "source": [
        "#### Test Chinese Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSYuDXHvPNKi",
        "outputId": "e5372308-78fe-4b48-f50c-a2306f8f20bf"
      },
      "source": [
        "sample_string = sample_examples[0][1]\n",
        "indices = subword_encoder_zh.encode(sample_string)\n",
        "print(sample_string)\n",
        "print(indices)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "[10, 151, 574, 1298, 6, 374, 55, 29, 193, 5, 1, 3, 3981, 931, 431, 125, 1, 17, 124, 33, 20, 97, 1089, 1247, 861, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVTQFS9bPQ2F"
      },
      "source": [
        "### Test 包含同語義的中英平行句子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXFznyQPPePN",
        "outputId": "3948218e-1410-44e2-a9d4-0e9aa0e6dade"
      },
      "source": [
        "en = \"The eurozone’s collapse forces a major realignment of European politics.\"\n",
        "zh = \"欧元区的瓦解强迫欧洲政治进行一次重大改组。\"\n",
        "\n",
        "# 將文字轉成為 subword indices\n",
        "en_indices = subword_encoder_en.encode(en)\n",
        "zh_indices = subword_encoder_zh.encode(zh)\n",
        "\n",
        "print(\"[英中原文]（轉換前）\")\n",
        "print(en)\n",
        "print(zh)\n",
        "print()\n",
        "print('-' * 20)\n",
        "print()\n",
        "print(\"[英中序列]（轉換後）\")\n",
        "print(en_indices)\n",
        "print(zh_indices)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[英中原文]（轉換前）\n",
            "The eurozone’s collapse forces a major realignment of European politics.\n",
            "欧元区的瓦解强迫欧洲政治进行一次重大改组。\n",
            "\n",
            "--------------------\n",
            "\n",
            "[英中序列]（轉換後）\n",
            "[16, 900, 11, 6, 1527, 874, 8, 230, 2259, 2728, 239, 3, 89, 1236, 7903]\n",
            "[44, 202, 168, 1, 852, 201, 231, 592, 44, 87, 17, 124, 106, 38, 7, 279, 86, 18, 212, 265, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDPbQuAgPjso"
      },
      "source": [
        "# 前處理數據"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQa3FZg5P81v"
      },
      "source": [
        "## 在一個序列的前後各加入一個特殊的 token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtNQJWinQDKQ"
      },
      "source": [
        "def encode(en_t, zh_t):\n",
        "  # 因為字典的索引從 0 開始，\n",
        "  # 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值\n",
        "  # 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值\n",
        "  en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(\n",
        "      en_t.numpy()) + [subword_encoder_en.vocab_size + 1]\n",
        "  # 同理，不過是使用中文字典的最後一個索引 + 1\n",
        "  zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(\n",
        "      zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
        "  \n",
        "  return en_indices, zh_indices"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSNWa-5kQHz0"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcfcNE0jQKR9",
        "outputId": "ba8b39f7-3965-4591-a2fd-6ac91634b2a5"
      },
      "source": [
        "en_t, zh_t = next(iter(train_examples))\n",
        "en_indices, zh_indices = encode(en_t, zh_t)\n",
        "print('英文 BOS 的 index：', subword_encoder_en.vocab_size)\n",
        "print('英文 EOS 的 index：', subword_encoder_en.vocab_size + 1)\n",
        "print('中文 BOS 的 index：', subword_encoder_zh.vocab_size)\n",
        "print('中文 EOS 的 index：', subword_encoder_zh.vocab_size + 1)\n",
        "\n",
        "print('\\n輸入為 2 個 Tensors：')\n",
        "pprint((en_t, zh_t))\n",
        "print('-' * 15)\n",
        "print('輸出為 2 個索引序列：')\n",
        "pprint((en_indices, zh_indices))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "英文 BOS 的 index： 8113\n",
            "英文 EOS 的 index： 8114\n",
            "中文 BOS 的 index： 4205\n",
            "中文 EOS 的 index： 4206\n",
            "\n",
            "輸入為 2 個 Tensors：\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'The fear is real and visceral, and politicians ignore it at their peril.'>,\n",
            " <tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82'>)\n",
            "---------------\n",
            "輸出為 2 個索引序列：\n",
            "([8113,\n",
            "  16,\n",
            "  1284,\n",
            "  9,\n",
            "  243,\n",
            "  5,\n",
            "  1275,\n",
            "  1756,\n",
            "  156,\n",
            "  1,\n",
            "  5,\n",
            "  1016,\n",
            "  5566,\n",
            "  21,\n",
            "  38,\n",
            "  33,\n",
            "  2982,\n",
            "  7965,\n",
            "  7903,\n",
            "  8114],\n",
            " [4205,\n",
            "  10,\n",
            "  151,\n",
            "  574,\n",
            "  1298,\n",
            "  6,\n",
            "  374,\n",
            "  55,\n",
            "  29,\n",
            "  193,\n",
            "  5,\n",
            "  1,\n",
            "  3,\n",
            "  3981,\n",
            "  931,\n",
            "  431,\n",
            "  125,\n",
            "  1,\n",
            "  17,\n",
            "  124,\n",
            "  33,\n",
            "  20,\n",
            "  97,\n",
            "  1089,\n",
            "  1247,\n",
            "  861,\n",
            "  3,\n",
            "  4206])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41KL-v8hQgO6"
      },
      "source": [
        "## 將剛剛定義的 encode 函式包成一個以 eager 模式執行的 TensorFlow Op"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQrLL6G8QjgQ",
        "outputId": "d430ffa5-5875-40dd-a1ff-4e8047d7f3f8"
      },
      "source": [
        "def tf_encode(en_t, zh_t):\n",
        "  # 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors\n",
        "  # 要到 `tf.py_funtion` 裡頭才是\n",
        "  # 另外因為索引都是整數，所以使用 `tf.int64`\n",
        "  return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])\n",
        "\n",
        "# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，\n",
        "# 我們會從頭建立一個正式的 `train_dataset`\n",
        "tmp_dataset = train_examples.map(tf_encode)\n",
        "en_indices, zh_indices = next(iter(tmp_dataset))\n",
        "print(en_indices)\n",
        "print(zh_indices)\n",
        "## tmp_dataset 的輸出已經是兩個索引序列，而非原文字串"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[8113   16 1284    9  243    5 1275 1756  156    1    5 1016 5566   21\n",
            "   38   33 2982 7965 7903 8114], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[4205   10  151  574 1298    6  374   55   29  193    5    1    3 3981\n",
            "  931  431  125    1   17  124   33   20   97 1089 1247  861    3 4206], shape=(28,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JM2wNwcQu0J"
      },
      "source": [
        "## 將長度超過 40 個 tokens 的序列都去掉"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8sdrrkYQvwZ"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
        "  # en, zh 分別代表英文與中文的索引序列\n",
        "  return tf.logical_and(tf.size(en) <= max_length,\n",
        "                        tf.size(zh) <= max_length)\n",
        "\n",
        "# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子\n",
        "tmp_dataset = tmp_dataset.filter(filter_max_length)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFBUMLp1Q1mQ"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV-CyPN_Q3Uz",
        "outputId": "cc463ea9-65b7-42d8-d5fa-a8aa94baa774"
      },
      "source": [
        "# 因為我們數據量小可以這樣 count\n",
        "num_examples = 0\n",
        "for en_indices, zh_indices in tmp_dataset:\n",
        "  cond1 = len(en_indices) <= MAX_LENGTH\n",
        "  cond2 = len(zh_indices) <= MAX_LENGTH\n",
        "  assert cond1 and cond2\n",
        "  num_examples += 1\n",
        "\n",
        "print(f\"所有英文與中文序列長度都不超過 {MAX_LENGTH} 個 tokens\")\n",
        "print(f\"訓練資料集裡總共有 {num_examples} 筆數據\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "所有英文與中文序列長度都不超過 40 個 tokens\n",
            "訓練資料集裡總共有 29784 筆數據\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkV4l7nXR2IU"
      },
      "source": [
        "## 將 batch 裡的所有序列都 pad 到同樣長度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5NxSlHVR4qJ",
        "outputId": "b7968869-7726-45e2-efd9-2e4a3bb0572e"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "# 將 batch 裡的所有序列都 pad 到同樣長度\n",
        "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
        "en_batch, zh_batch = next(iter(tmp_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113   16 1284 ...    0    0    0]\n",
            " [8113 1894 1302 ...    0    0    0]\n",
            " [8113   44   40 ...    0    0    0]\n",
            " ...\n",
            " [8113  122  506 ...    0    0    0]\n",
            " [8113   16  215 ...    0    0    0]\n",
            " [8113 7443 7889 ...    0    0    0]], shape=(64, 39), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   10  151 ...    0    0    0]\n",
            " [4205  206  275 ...    0    0    0]\n",
            " [4205    5   10 ...    0    0    0]\n",
            " ...\n",
            " [4205   34    6 ...    0    0    0]\n",
            " [4205  317  256 ...    0    0    0]\n",
            " [4205  167  326 ...    0    0    0]], shape=(64, 40), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zdu_fZVSFSr"
      },
      "source": [
        "## 從頭建立訓練集與驗證集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2NnmHPUSGRg"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 15000\n",
        "\n",
        "# 訓練集\n",
        "train_dataset = (train_examples  # 輸出：(英文句子, 中文句子)\n",
        "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
        "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
        "                 .cache() # 加快讀取數據\n",
        "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
        "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
        "                               padded_shapes=([-1], [-1]))\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
        "# 驗證集\n",
        "val_dataset = (val_examples\n",
        "               .map(tf_encode)\n",
        "               .filter(filter_max_length)\n",
        "               .padded_batch(BATCH_SIZE, \n",
        "                             padded_shapes=([-1], [-1])))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCgpANKnSKZ5"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMgLD7urSMKZ",
        "outputId": "376c4ee3-10aa-4712-a0aa-b726c5a0f758"
      },
      "source": [
        "en_batch, zh_batch = next(iter(train_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113 1381 3806 ...    0    0    0]\n",
            " [8113   16 2695 ...    0    0    0]\n",
            " [8113  279  110 ...    0    0    0]\n",
            " ...\n",
            " [8113 6109 4297 ...    0    0    0]\n",
            " [8113 3512   47 ...    0    0    0]\n",
            " [8113  190 3298 ...    0    0    0]], shape=(128, 39), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   41  474 ...    0    0    0]\n",
            " [4205   56  503 ...    0    0    0]\n",
            " [4205   76   97 ...    0    0    0]\n",
            " ...\n",
            " [4205   48   64 ...    0    0    0]\n",
            " [4205  631   43 ...  634    3 4206]\n",
            " [4205   16    4 ...    0    0    0]], shape=(128, 40), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbNy3JYUcFcX"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKjlfNblcmaO"
      },
      "source": [
        "## 建立兩個要拿來持續追蹤的中英平行句子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NptxGN4jco61",
        "outputId": "99dc1f78-8417-454c-f05f-14c0ca69f5dd"
      },
      "source": [
        "demo_examples = [\n",
        "    (\"It is important.\", \"这很重要。\"),\n",
        "    (\"The numbers speak for themselves.\", \"数字证明了一切。\"),\n",
        "]\n",
        "pprint(demo_examples)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('It is important.', '这很重要。'),\n",
            " ('The numbers speak for themselves.', '数字证明了一切。')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ykaLdicwxG",
        "outputId": "f2801d24-bb31-48e0-e49e-1c197bc9c527"
      },
      "source": [
        "batch_size = 2\n",
        "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
        "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
        "))\n",
        "\n",
        "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
        "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
        "demo_dataset = demo_examples.map(tf_encode)\\\n",
        "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
        "\n",
        "# 取出這個 demo dataset 裡唯一一個 batch\n",
        "inp, tar = next(iter(demo_dataset))\n",
        "print('inp:', inp)\n",
        "print('' * 10)\n",
        "print('tar:', tar)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "\n",
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfPs7p6Sc4xt"
      },
      "source": [
        "## 視覺化 3 維詞嵌入張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAjg7lp0c5nW",
        "outputId": "c5334b3a-2b1b-484d-9d8b-063b89947aff"
      },
      "source": [
        "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
        "vocab_size_en = subword_encoder_en.vocab_size + 2\n",
        "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
        "d_model = 4\n",
        "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en, d_model)\n",
        "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
        "\n",
        "emb_inp = embedding_layer_en(inp)\n",
        "emb_tar = embedding_layer_zh(tar)\n",
        "emb_inp, emb_tar"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              " array([[[ 0.02807367,  0.03455831, -0.00592906,  0.02499617],\n",
              "         [ 0.01432918,  0.02194908, -0.03300651, -0.00862454],\n",
              "         [ 0.04628053,  0.0115247 , -0.0049338 ,  0.01226263],\n",
              "         [-0.02770383, -0.02904369, -0.04239569,  0.04483496],\n",
              "         [ 0.01210568,  0.01186813, -0.00836542,  0.00577604],\n",
              "         [-0.02502134, -0.04595632, -0.04937274,  0.04308422],\n",
              "         [-0.00668443,  0.03884761,  0.0326353 , -0.04964892],\n",
              "         [-0.00668443,  0.03884761,  0.0326353 , -0.04964892]],\n",
              " \n",
              "        [[ 0.02807367,  0.03455831, -0.00592906,  0.02499617],\n",
              "         [ 0.02898879,  0.03546881,  0.02735504,  0.0322384 ],\n",
              "         [ 0.01250697,  0.00058944,  0.01443725,  0.00879383],\n",
              "         [ 0.03890349,  0.03687091, -0.0491871 ,  0.03005183],\n",
              "         [ 0.01068056,  0.01234149, -0.04494428, -0.00480147],\n",
              "         [ 0.02367078,  0.03079415,  0.02275873,  0.03091809],\n",
              "         [ 0.01210568,  0.01186813, -0.00836542,  0.00577604],\n",
              "         [-0.02502134, -0.04595632, -0.04937274,  0.04308422]]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(2, 10, 4), dtype=float32, numpy=\n",
              " array([[[-0.02282319, -0.01055995,  0.04843744,  0.00783952],\n",
              "         [-0.01079856, -0.03693919,  0.04829888, -0.01448965],\n",
              "         [ 0.04000619, -0.02590526, -0.02988156, -0.01879985],\n",
              "         [ 0.00214509,  0.00248455,  0.02427474,  0.00176178],\n",
              "         [-0.01569381, -0.03003497, -0.03855526, -0.02174056],\n",
              "         [ 0.0400285 , -0.0332581 , -0.0009184 ,  0.03477527],\n",
              "         [ 0.02867664,  0.01880774,  0.03228236, -0.01565862],\n",
              "         [-0.02838035,  0.01158942, -0.02495556, -0.02071409],\n",
              "         [-0.02838035,  0.01158942, -0.02495556, -0.02071409],\n",
              "         [-0.02838035,  0.01158942, -0.02495556, -0.02071409]],\n",
              " \n",
              "        [[-0.02282319, -0.01055995,  0.04843744,  0.00783952],\n",
              "         [ 0.01627392,  0.03977975, -0.00313966, -0.00550129],\n",
              "         [-0.0023957 , -0.04361086, -0.02027133,  0.04017763],\n",
              "         [ 0.02209036, -0.01153525,  0.03878719, -0.04587317],\n",
              "         [-0.00930882, -0.01075454, -0.02002564,  0.00003041],\n",
              "         [-0.02127123, -0.02358091, -0.03141426, -0.03459009],\n",
              "         [ 0.01321514, -0.00758296,  0.03461019,  0.0250724 ],\n",
              "         [-0.03315058, -0.03677864,  0.02746859,  0.02740859],\n",
              "         [ 0.0400285 , -0.0332581 , -0.0009184 ,  0.03477527],\n",
              "         [ 0.02867664,  0.01880774,  0.03228236, -0.01565862]]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq7k9DTjdAyZ",
        "outputId": "d95c3c45-eb57-4d1c-8b83-ad426b9172b1"
      },
      "source": [
        "print(\"tar[0]:\", tar[0][-3:])\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_tar[0]:\", emb_tar[0][-3:])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar[0]: tf.Tensor([0 0 0], shape=(3,), dtype=int64)\n",
            "--------------------\n",
            "emb_tar[0]: tf.Tensor(\n",
            "[[-0.02838035  0.01158942 -0.02495556 -0.02071409]\n",
            " [-0.02838035  0.01158942 -0.02495556 -0.02071409]\n",
            " [-0.02838035  0.01158942 -0.02495556 -0.02071409]], shape=(3, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnkXx4WhdIPm"
      },
      "source": [
        "## 遮罩（masking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNefSfL0dNVY"
      },
      "source": [
        "padding mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rEEa0ovdJ8N",
        "outputId": "738e0aa5-2fd5-489d-ae12-a97f3a438494"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "inp_mask = create_padding_mask(inp)\n",
        "inp_mask"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1, 1, 8), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEj89lLSdR0b",
        "outputId": "7c65c686-a206-4983-918e-d075cb53283e"
      },
      "source": [
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tf.squeeze(inp_mask):\", tf.squeeze(inp_mask))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "tf.squeeze(inp_mask): tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKTv9pZFdXQp"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q18lkFMpdYM6",
        "outputId": "685d938e-0749-4643-f98e-85728d3369f5"
      },
      "source": [
        "# 設定一個 seed 確保我們每次都拿到一樣的隨機結果\n",
        "tf.random.set_seed(9527)\n",
        "\n",
        "# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`\n",
        "q = emb_inp\n",
        "k = emb_inp\n",
        "# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector\n",
        "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)\n",
        "v"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              "array([[[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.]],\n",
              "\n",
              "       [[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vqOLBAfdphx"
      },
      "source": [
        " scaled dot product attention 在 TensorFlow 裡是怎麼被實作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z0fkIQ8duVo"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  # 將 `q`、 `k` 做點積再 scale\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)  # 取得 seq_k 的序列長度\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
        "\n",
        "  # 將遮罩「加」到被丟入 softmax 前的 logits\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # 以注意權重對 v 做加權平均（weighted average）\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-W_pRoYdjtY"
      },
      "source": [
        "假設沒有遮罩的存在"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iQrYZlZdlyE",
        "outputId": "d00893c3-6aec-488d-a5c1-dfd0e0c86ad4"
      },
      "source": [
        "mask = None\n",
        "output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"output:\", output)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output: tf.Tensor(\n",
            "[[[0.3750844  0.3748821  0.3749017  0.49997115]\n",
            "  [0.37500083 0.37500525 0.37493622 0.50002927]\n",
            "  [0.37504837 0.37488845 0.3748818  0.50001633]\n",
            "  [0.37528503 0.37506896 0.3750264  0.5000073 ]\n",
            "  [0.3750279  0.37496698 0.37495765 0.5000004 ]\n",
            "  [0.3753038  0.37509248 0.37502626 0.5000333 ]\n",
            "  [0.3747037  0.37500647 0.37503937 0.49997255]\n",
            "  [0.3747037  0.37500647 0.37503937 0.49997255]]\n",
            "\n",
            " [[0.62523705 0.25000706 0.62514794 0.37507454]\n",
            "  [0.6253935  0.2500028  0.6251825  0.3750856 ]\n",
            "  [0.6251143  0.24999383 0.6250446  0.37501097]\n",
            "  [0.6251043  0.250002   0.6251663  0.37506598]\n",
            "  [0.6248883  0.25001392 0.6249963  0.37502006]\n",
            "  [0.62533635 0.24999917 0.6251669  0.37507024]\n",
            "  [0.625059   0.25000522 0.62504184 0.3750273 ]\n",
            "  [0.62457716 0.2499084  0.6250595  0.37482446]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "attention_weights: tf.Tensor(\n",
            "[[[0.12512714 0.12503324 0.12508903 0.12493636 0.12502092 0.12490441\n",
            "   0.12494446 0.12494446]\n",
            "  [0.12503451 0.1250789  0.12502402 0.12496184 0.12500446 0.12495638\n",
            "   0.12496994 0.12496994]\n",
            "  [0.12510188 0.1250356  0.12512791 0.12492117 0.12502533 0.12491755\n",
            "   0.12493531 0.12493531]\n",
            "  [0.1249663  0.12499053 0.12493829 0.125331   0.12498774 0.12537074\n",
            "   0.12470769 0.12470769]\n",
            "  [0.12504187 0.12502414 0.12503344 0.12497871 0.12500729 0.12497122\n",
            "   0.12497164 0.12497164]\n",
            "  [0.12494049 0.12499122 0.12494082 0.12537691 0.12498639 0.1254383\n",
            "   0.12466297 0.12466297]\n",
            "  [0.12498807 0.1250123  0.12496608 0.12472131 0.12499432 0.12467047\n",
            "   0.12532371 0.12532371]\n",
            "  [0.12498807 0.1250123  0.12496608 0.12472131 0.12499432 0.12467047\n",
            "   0.12532371 0.12532371]]\n",
            "\n",
            " [[0.12506747 0.12507002 0.12493393 0.12511542 0.12495685 0.12505022\n",
            "   0.1249613  0.12484483]\n",
            "  [0.12508279 0.12515804 0.12498144 0.12504375 0.12487532 0.12512748\n",
            "   0.12496065 0.12477047]\n",
            "  [0.12501714 0.1250519  0.12501317 0.12498943 0.12495113 0.12504269\n",
            "   0.12499105 0.12494341]\n",
            "  [0.12506399 0.12497959 0.12485489 0.12523834 0.12503447 0.12496753\n",
            "   0.12494426 0.12491689]\n",
            "  [0.12500614 0.12491181 0.12491721 0.12513521 0.12509596 0.12491795\n",
            "   0.12499058 0.1250252 ]\n",
            "  [0.12507108 0.12513559 0.12498032 0.12503979 0.12488955 0.12510961\n",
            "   0.12496317 0.12481086]\n",
            "  [0.1250221  0.12500867 0.12496863 0.12505646 0.1250021  0.12500311\n",
            "   0.12498753 0.12495146]\n",
            "  [0.12491605 0.12482888 0.12493147 0.12503955 0.12504719 0.12486121\n",
            "   0.12496193 0.12541376]]], shape=(2, 8, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQZ_qp-xeLu7"
      },
      "source": [
        "為何遮罩要放在 softmax 之前而不能放之後？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLKUCzMnec8F",
        "outputId": "6d5d04f4-477e-4e54-f714-1071caa54192"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "inp_mask = create_padding_mask(inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_mask:\", inp_mask)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "inp_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rStJGcnAemZd",
        "outputId": "cc8ae429-1914-45f3-8b1f-55e93beb7762"
      },
      "source": [
        "# 這次讓我們將 padding mask 放入注意函式並觀察\n",
        "# 注意權重的變化\n",
        "mask = tf.squeeze(inp_mask, axis=1) # (batch_size, 1, seq_len_q)\n",
        "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[0.16681147 0.16668628 0.16676068 0.16655713 0.16666988 0.16651453\n",
            "   0.         0.        ]\n",
            "  [0.16669932 0.16675851 0.16668534 0.16660243 0.16665927 0.16659516\n",
            "   0.         0.        ]\n",
            "  [0.16677374 0.16668537 0.16680844 0.16653283 0.1666717  0.16652802\n",
            "   0.         0.        ]\n",
            "  [0.16649197 0.16652425 0.16645464 0.16697784 0.16652052 0.1670308\n",
            "   0.         0.        ]\n",
            "  [0.16670991 0.16668627 0.16669868 0.16662571 0.16666381 0.16661571\n",
            "   0.         0.        ]\n",
            "  [0.1664377  0.16650528 0.16643815 0.16701907 0.16649885 0.16710086\n",
            "   0.         0.        ]\n",
            "  [0.16679476 0.16682708 0.1667654  0.16643879 0.16680309 0.16637091\n",
            "   0.         0.        ]\n",
            "  [0.16679476 0.16682708 0.1667654  0.16643879 0.16680309 0.16637091\n",
            "   0.         0.        ]]\n",
            "\n",
            " [[0.12506747 0.12507002 0.12493393 0.12511542 0.12495685 0.12505022\n",
            "   0.1249613  0.12484483]\n",
            "  [0.12508279 0.12515804 0.12498144 0.12504375 0.12487532 0.12512748\n",
            "   0.12496065 0.12477047]\n",
            "  [0.12501714 0.1250519  0.12501317 0.12498943 0.12495113 0.12504269\n",
            "   0.12499105 0.12494341]\n",
            "  [0.12506399 0.12497959 0.12485489 0.12523834 0.12503447 0.12496753\n",
            "   0.12494426 0.12491689]\n",
            "  [0.12500614 0.12491181 0.12491721 0.12513521 0.12509596 0.12491795\n",
            "   0.12499058 0.1250252 ]\n",
            "  [0.12507108 0.12513559 0.12498032 0.12503979 0.12488955 0.12510961\n",
            "   0.12496317 0.12481086]\n",
            "  [0.1250221  0.12500867 0.12496863 0.12505646 0.1250021  0.12500311\n",
            "   0.12498753 0.12495146]\n",
            "  [0.12491605 0.12482888 0.12493147 0.12503955 0.12504719 0.12486121\n",
            "   0.12496193 0.12541376]]], shape=(2, 8, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MN9XggeeseW",
        "outputId": "1b4aaebd-3f4a-4596-ddf8-a6e77a5f33dc"
      },
      "source": [
        "# 事實上也不完全是上句話的翻譯，\n",
        "# 因為我們在第一個維度還是把兩個句子都拿出來方便你比較\n",
        "attention_weights[:, :, -2:]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 8, 2), dtype=float32, numpy=\n",
              "array([[[0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ]],\n",
              "\n",
              "       [[0.1249613 , 0.12484483],\n",
              "        [0.12496065, 0.12477047],\n",
              "        [0.12499105, 0.12494341],\n",
              "        [0.12494426, 0.12491689],\n",
              "        [0.12499058, 0.1250252 ],\n",
              "        [0.12496317, 0.12481086],\n",
              "        [0.12498753, 0.12495146],\n",
              "        [0.12496193, 0.12541376]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDslo8oZewLN"
      },
      "source": [
        "第一個英文句子的最後 2 個位置因為是 <pad> 所以被遮罩「蓋住」而沒有權重值（上方 2 維陣列）；第二個句子的序列（下方 2 維陣列）則因為最後 2 個位置仍是正常的英文子詞，因此都有被其他子詞關注。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y469uqse0CF"
      },
      "source": [
        "look ahead mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLSwx1Mbe09G",
        "outputId": "66804237-ddda-4283-abb7-cb09bb1557b9"
      },
      "source": [
        "# 建立一個 2 維矩陣，維度為 (size, size)，\n",
        "# 其遮罩為一個右上角的三角形\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "seq_len = emb_tar.shape[1] # 注意這次我們用中文的詞嵌入張量 `emb_tar`\n",
        "look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask\", look_ahead_mask)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[-0.02282319 -0.01055995  0.04843744  0.00783952]\n",
            "  [-0.01079856 -0.03693919  0.04829888 -0.01448965]\n",
            "  [ 0.04000619 -0.02590526 -0.02988156 -0.01879985]\n",
            "  [ 0.00214509  0.00248455  0.02427474  0.00176178]\n",
            "  [-0.01569381 -0.03003497 -0.03855526 -0.02174056]\n",
            "  [ 0.0400285  -0.0332581  -0.0009184   0.03477527]\n",
            "  [ 0.02867664  0.01880774  0.03228236 -0.01565862]\n",
            "  [-0.02838035  0.01158942 -0.02495556 -0.02071409]\n",
            "  [-0.02838035  0.01158942 -0.02495556 -0.02071409]\n",
            "  [-0.02838035  0.01158942 -0.02495556 -0.02071409]]\n",
            "\n",
            " [[-0.02282319 -0.01055995  0.04843744  0.00783952]\n",
            "  [ 0.01627392  0.03977975 -0.00313966 -0.00550129]\n",
            "  [-0.0023957  -0.04361086 -0.02027133  0.04017763]\n",
            "  [ 0.02209036 -0.01153525  0.03878719 -0.04587317]\n",
            "  [-0.00930882 -0.01075454 -0.02002564  0.00003041]\n",
            "  [-0.02127123 -0.02358091 -0.03141426 -0.03459009]\n",
            "  [ 0.01321514 -0.00758296  0.03461019  0.0250724 ]\n",
            "  [-0.03315058 -0.03677864  0.02746859  0.02740859]\n",
            "  [ 0.0400285  -0.0332581  -0.0009184   0.03477527]\n",
            "  [ 0.02867664  0.01880774  0.03228236 -0.01565862]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgS2IzV5e74e",
        "outputId": "86a97e5c-45e7-49ab-929c-a2d6929aa1cd"
      },
      "source": [
        "# 讓我們用目標語言（中文）的 batch\n",
        "# 來模擬 Decoder 處理的情況\n",
        "temp_q = temp_k = emb_tar\n",
        "temp_v = tf.cast(tf.math.greater(\n",
        "    tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
        "\n",
        "# 將 look_ahead_mask 放入注意函式\n",
        "_, attention_weights = scaled_dot_product_attention(\n",
        "    temp_q, temp_k, temp_v, look_ahead_mask)\n",
        "\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_weights: tf.Tensor(\n",
            "[[[1.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.49985483 0.5001452  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.33292553 0.33319005 0.33388445 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.2500764  0.2500661  0.24984501 0.2500125  0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.19982165 0.19993101 0.20012897 0.19984964 0.20026876 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.16656435 0.16661285 0.16674525 0.1665957  0.16656305 0.1669189\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.1428714  0.14288525 0.14282867 0.14289115 0.14269242 0.14282571\n",
            "   0.14300545 0.         0.         0.        ]\n",
            "  [0.12496775 0.12495644 0.12500183 0.12497846 0.12511502 0.12488198\n",
            "   0.12495329 0.12514517 0.         0.        ]\n",
            "  [0.11106811 0.11105806 0.1110984  0.11107764 0.111199   0.11099189\n",
            "   0.11105527 0.1112258  0.1112258  0.        ]\n",
            "  [0.09995098 0.09994194 0.09997825 0.09995955 0.10006877 0.09988239\n",
            "   0.09993942 0.10009289 0.10009289 0.10009289]]\n",
            "\n",
            " [[1.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.4996407  0.50035924 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.33320504 0.33290872 0.33388624 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.25004134 0.24990317 0.24962713 0.25042835 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.19994599 0.1999587  0.20010023 0.1999244  0.2000707  0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.16654077 0.16654603 0.16665612 0.16664311 0.1667189  0.16689506\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.1429571  0.14281532 0.14288232 0.14287996 0.14278671 0.1426923\n",
            "   0.14298622 0.         0.         0.        ]\n",
            "  [0.1251093  0.12480129 0.12508038 0.1249099  0.1249508  0.12492622\n",
            "   0.12503353 0.12518859 0.         0.        ]\n",
            "  [0.11105338 0.11102419 0.1112259  0.11105178 0.11107219 0.11100303\n",
            "   0.11116201 0.11111771 0.11128977 0.        ]\n",
            "  [0.10002162 0.10005223 0.09988368 0.10011165 0.09993644 0.09991597\n",
            "   0.10004029 0.09993301 0.09998965 0.10011547]]], shape=(2, 10, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4g3RQx2fBA0",
        "outputId": "68629da4-063d-485c-c252-49fcaf12cf4c"
      },
      "source": [
        "attention_weights[:, 0, :]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTJOfse-fJ2I"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ATr1z1ZfYLV"
      },
      "source": [
        "### 先把一個 head 變成多個 heads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCf7cIw3fKzU",
        "outputId": "4bb0c369-a334-41f8-f81f-ffd429ae6b52"
      },
      "source": [
        "def split_heads(x, d_model, num_heads):\n",
        "  # x.shape: (batch_size, seq_len, d_model)\n",
        "  batch_size = tf.shape(x)[0]\n",
        "  \n",
        "  # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
        "  assert d_model % num_heads == 0\n",
        "  depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度 \n",
        "  \n",
        "  # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
        "  # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
        "  # (batch_size, seq_len, num_heads, depth)\n",
        "  reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
        "  \n",
        "  # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
        "  # (batch_size, num_heads, seq_len, depth)\n",
        "  output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
        "  \n",
        "  return output\n",
        "\n",
        "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
        "d_model = 4\n",
        "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
        "num_heads = 2\n",
        "x = emb_inp\n",
        "\n",
        "output = split_heads(x, d_model, num_heads)  \n",
        "print(\"x:\", x)\n",
        "print(\"output:\", output)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: tf.Tensor(\n",
            "[[[ 0.02807367  0.03455831 -0.00592906  0.02499617]\n",
            "  [ 0.01432918  0.02194908 -0.03300651 -0.00862454]\n",
            "  [ 0.04628053  0.0115247  -0.0049338   0.01226263]\n",
            "  [-0.02770383 -0.02904369 -0.04239569  0.04483496]\n",
            "  [ 0.01210568  0.01186813 -0.00836542  0.00577604]\n",
            "  [-0.02502134 -0.04595632 -0.04937274  0.04308422]\n",
            "  [-0.00668443  0.03884761  0.0326353  -0.04964892]\n",
            "  [-0.00668443  0.03884761  0.0326353  -0.04964892]]\n",
            "\n",
            " [[ 0.02807367  0.03455831 -0.00592906  0.02499617]\n",
            "  [ 0.02898879  0.03546881  0.02735504  0.0322384 ]\n",
            "  [ 0.01250697  0.00058944  0.01443725  0.00879383]\n",
            "  [ 0.03890349  0.03687091 -0.0491871   0.03005183]\n",
            "  [ 0.01068056  0.01234149 -0.04494428 -0.00480147]\n",
            "  [ 0.02367078  0.03079415  0.02275873  0.03091809]\n",
            "  [ 0.01210568  0.01186813 -0.00836542  0.00577604]\n",
            "  [-0.02502134 -0.04595632 -0.04937274  0.04308422]]], shape=(2, 8, 4), dtype=float32)\n",
            "output: tf.Tensor(\n",
            "[[[[ 0.02807367  0.03455831]\n",
            "   [ 0.01432918  0.02194908]\n",
            "   [ 0.04628053  0.0115247 ]\n",
            "   [-0.02770383 -0.02904369]\n",
            "   [ 0.01210568  0.01186813]\n",
            "   [-0.02502134 -0.04595632]\n",
            "   [-0.00668443  0.03884761]\n",
            "   [-0.00668443  0.03884761]]\n",
            "\n",
            "  [[-0.00592906  0.02499617]\n",
            "   [-0.03300651 -0.00862454]\n",
            "   [-0.0049338   0.01226263]\n",
            "   [-0.04239569  0.04483496]\n",
            "   [-0.00836542  0.00577604]\n",
            "   [-0.04937274  0.04308422]\n",
            "   [ 0.0326353  -0.04964892]\n",
            "   [ 0.0326353  -0.04964892]]]\n",
            "\n",
            "\n",
            " [[[ 0.02807367  0.03455831]\n",
            "   [ 0.02898879  0.03546881]\n",
            "   [ 0.01250697  0.00058944]\n",
            "   [ 0.03890349  0.03687091]\n",
            "   [ 0.01068056  0.01234149]\n",
            "   [ 0.02367078  0.03079415]\n",
            "   [ 0.01210568  0.01186813]\n",
            "   [-0.02502134 -0.04595632]]\n",
            "\n",
            "  [[-0.00592906  0.02499617]\n",
            "   [ 0.02735504  0.0322384 ]\n",
            "   [ 0.01443725  0.00879383]\n",
            "   [-0.0491871   0.03005183]\n",
            "   [-0.04494428 -0.00480147]\n",
            "   [ 0.02275873  0.03091809]\n",
            "   [-0.00836542  0.00577604]\n",
            "   [-0.04937274  0.04308422]]]], shape=(2, 2, 8, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJjjqAWfiRT"
      },
      "source": [
        "### multi-head attention 的實現"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1IzVwO8fjpK"
      },
      "source": [
        "# 實作一個執行多頭注意力機制的 keras layer\n",
        "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
        "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
        "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
        "# output.shape            == (batch_size, seq_len_q, d_model)\n",
        "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  # 在初始的時候建立一些必要參數\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads # 指定要將 `d_model` 拆成幾個 heads\n",
        "    self.d_model = d_model # 在 split_heads 之前的基底維度\n",
        "    \n",
        "    assert d_model % self.num_heads == 0  # 前面看過，要確保可以平分\n",
        "    \n",
        "    self.depth = d_model // self.num_heads  # 每個 head 裡子詞的新的 repr. 維度\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)  # 分別給 q, k, v 的 3 個線性轉換 \n",
        "    self.wk = tf.keras.layers.Dense(d_model)  # 注意我們並沒有指定 activation func\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)  # 多 heads 串接後通過的線性轉換\n",
        "  \n",
        "  # 這跟我們前面看過的函式有 87% 相似\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "  \n",
        "  # multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    # 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    # 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制\n",
        "    # 輸出會多一個 head 維度\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    \n",
        "    # 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape\n",
        "    # 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model)) \n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # 通過最後一個線性轉換\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuZnQELqfzMr",
        "outputId": "c36a98cc-79bc-4833-feb5-1f35498099a0"
      },
      "source": [
        "# emb_inp.shape == (batch_size, seq_len, d_model)\n",
        "#               == (2, 8, 4)\n",
        "assert d_model == emb_inp.shape[-1]  == 4\n",
        "num_heads = 2\n",
        "\n",
        "print(f\"d_model: {d_model}\")\n",
        "print(f\"num_heads: {num_heads}\\n\")\n",
        "\n",
        "# 初始化一個 multi-head attention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# 簡單將 v, k, q 都設置為 `emb_inp`\n",
        "# 順便看看 padding mask 的作用。\n",
        "# 別忘記，第一個英文序列的最後兩個 tokens 是 <pad>\n",
        "v = k = q = emb_inp\n",
        "padding_mask = create_padding_mask(inp)\n",
        "print(\"q.shape:\", q.shape)\n",
        "print(\"k.shape:\", k.shape)\n",
        "print(\"v.shape:\", v.shape)\n",
        "print(\"padding_mask.shape:\", padding_mask.shape)\n",
        "\n",
        "output, attention_weights = mha(v, k, q, mask)\n",
        "print(\"output.shape:\", output.shape)\n",
        "print(\"attention_weights.shape:\", attention_weights.shape)\n",
        "\n",
        "print(\"\\noutput:\", output)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_model: 4\n",
            "num_heads: 2\n",
            "\n",
            "q.shape: (2, 8, 4)\n",
            "k.shape: (2, 8, 4)\n",
            "v.shape: (2, 8, 4)\n",
            "padding_mask.shape: (2, 1, 1, 8)\n",
            "output.shape: (2, 8, 4)\n",
            "attention_weights.shape: (2, 2, 8, 8)\n",
            "\n",
            "output: tf.Tensor(\n",
            "[[[ 0.00916386 -0.00908436 -0.00758396  0.00172248]\n",
            "  [ 0.00914001 -0.00906638 -0.00759064  0.00170149]\n",
            "  [ 0.00915664 -0.00907908 -0.00758855  0.0017134 ]\n",
            "  [ 0.00918463 -0.00910074 -0.00755325  0.00176537]\n",
            "  [ 0.00915916 -0.00908091 -0.00758137  0.00172265]\n",
            "  [ 0.00918326 -0.00909988 -0.00755194  0.00176564]\n",
            "  [ 0.00914194 -0.00906726 -0.00759496  0.00170076]\n",
            "  [ 0.00914194 -0.00906726 -0.00759496  0.00170076]]\n",
            "\n",
            " [[-0.00662936  0.00738125  0.01306719  0.00949379]\n",
            "  [-0.00662197  0.00737575  0.01306622  0.00949617]\n",
            "  [-0.00663221  0.00738288  0.01307552  0.00950348]\n",
            "  [-0.00663212  0.007382    0.01306047  0.00948655]\n",
            "  [-0.00664668  0.00739465  0.0130782   0.00949801]\n",
            "  [-0.00662361  0.00737754  0.01306951  0.00949827]\n",
            "  [-0.00663744  0.00738769  0.01307673  0.00950077]\n",
            "  [-0.0066317   0.00738732  0.01309728  0.0095199 ]]], shape=(2, 8, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A216_jx4gBKL"
      },
      "source": [
        "## Position-wise Feed-Forward Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGrLRAgjgCqZ"
      },
      "source": [
        "# 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  \n",
        "  # 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHiUmmdxgIZx"
      },
      "source": [
        "### 建立一個 FFN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1LpEOQgJV8",
        "outputId": "0b91a6e1-b541-4218-ae12-f5d450dbcb75"
      },
      "source": [
        "batch_size = 64\n",
        "seq_len = 10\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "\n",
        "x = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "out = ffn(x)\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"out.shape:\", out.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (64, 10, 512)\n",
            "out.shape: (64, 10, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6JR_8CIgOIN",
        "outputId": "0b2df20f-fae7-41d7-a510-9c3f8704476c"
      },
      "source": [
        "d_model = 4 # FFN 的輸入輸出張量的最後一維皆為 `d_model`\n",
        "dff = 6\n",
        "\n",
        "# 建立一個小 FFN\n",
        "small_ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "# 懂子詞梗的站出來\n",
        "dummy_sentence = tf.constant([[5, 5, 6, 6], \n",
        "                              [5, 5, 6, 6], \n",
        "                              [9, 5, 2, 7], \n",
        "                              [9, 5, 2, 7],\n",
        "                              [9, 5, 2, 7]], dtype=tf.float32)\n",
        "small_ffn(dummy_sentence)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
              "       [ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
              "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ],\n",
              "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ],\n",
              "       [ 3.6502066 , -0.97325826, -2.4126563 , -6.509499  ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWPtLWY_gR_F"
      },
      "source": [
        "# Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Y2JDm2gUPo"
      },
      "source": [
        "# Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA & FFN\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  # Transformer 論文內預設 dropout rate 為 0.1\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    # 一樣，一個 sub-layer 一個 dropout layer\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  # 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同\n",
        "  def call(self, x, training, mask):\n",
        "    # 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)\n",
        "    # attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)\n",
        "    \n",
        "    # sub-layer 1: MHA\n",
        "    # Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己\n",
        "    # 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 <pad> token\n",
        "    attn_output, attn = self.mha(x, x, x, mask)  \n",
        "    attn_output = self.dropout1(attn_output, training=training) \n",
        "    out1 = self.layernorm1(x + attn_output)  \n",
        "    \n",
        "    # sub-layer 2: FFN\n",
        "    ffn_output = self.ffn(out1) \n",
        "    ffn_output = self.dropout2(ffn_output, training=training)  # 記得 training\n",
        "    out2 = self.layernorm2(out1 + ffn_output)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTMPy3ujgcxJ",
        "outputId": "a3304c98-3bbd-48f2-c02d-df2db9674f3a"
      },
      "source": [
        "# 之後可以調的超參數。這邊為了 demo 設小一點\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# 新建一個使用上述參數的 Encoder Layer\n",
        "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
        "padding_mask = create_padding_mask(inp)  # 建立一個當前輸入 batch 使用的 padding mask\n",
        "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"padding_mask:\", padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_inp:\", emb_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "assert emb_inp.shape == enc_out.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
            "--------------------\n",
            "emb_inp: tf.Tensor(\n",
            "[[[ 0.02807367  0.03455831 -0.00592906  0.02499617]\n",
            "  [ 0.01432918  0.02194908 -0.03300651 -0.00862454]\n",
            "  [ 0.04628053  0.0115247  -0.0049338   0.01226263]\n",
            "  [-0.02770383 -0.02904369 -0.04239569  0.04483496]\n",
            "  [ 0.01210568  0.01186813 -0.00836542  0.00577604]\n",
            "  [-0.02502134 -0.04595632 -0.04937274  0.04308422]\n",
            "  [-0.00668443  0.03884761  0.0326353  -0.04964892]\n",
            "  [-0.00668443  0.03884761  0.0326353  -0.04964892]]\n",
            "\n",
            " [[ 0.02807367  0.03455831 -0.00592906  0.02499617]\n",
            "  [ 0.02898879  0.03546881  0.02735504  0.0322384 ]\n",
            "  [ 0.01250697  0.00058944  0.01443725  0.00879383]\n",
            "  [ 0.03890349  0.03687091 -0.0491871   0.03005183]\n",
            "  [ 0.01068056  0.01234149 -0.04494428 -0.00480147]\n",
            "  [ 0.02367078  0.03079415  0.02275873  0.03091809]\n",
            "  [ 0.01210568  0.01186813 -0.00836542  0.00577604]\n",
            "  [-0.02502134 -0.04595632 -0.04937274  0.04308422]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.7180352   1.4323909  -1.1244874   0.4101316 ]\n",
            "  [-0.3731438   1.4403491  -1.3135681   0.24636279]\n",
            "  [ 0.42396766  1.0011508  -1.6618913   0.23677291]\n",
            "  [-1.0246521   0.63965714 -0.91809016  1.3030851 ]\n",
            "  [-0.8036809   1.462118   -1.0361613   0.37772405]\n",
            "  [-0.7380138   0.2602049  -1.0404452   1.518254  ]\n",
            "  [-0.4572801   1.7195784  -0.49469924 -0.7675989 ]\n",
            "  [-0.4572801   1.7195784  -0.49469924 -0.7675989 ]]\n",
            "\n",
            " [[-0.3841815   1.314565   -1.384842    0.45445853]\n",
            "  [-0.9826494   1.3677015  -0.93065137  0.5455992 ]\n",
            "  [ 0.84805155 -1.64579     0.04250942  0.75522894]\n",
            "  [-0.16514704  1.202444   -1.5158596   0.4785626 ]\n",
            "  [-0.11437728  1.2537354  -1.5093584   0.37000015]\n",
            "  [-1.0233918   1.2666937  -0.9336101   0.6903083 ]\n",
            "  [-0.24762936  1.2683611  -1.4614152   0.44068357]\n",
            "  [-0.31614232 -0.19741783 -1.1087236   1.6222838 ]]], shape=(2, 8, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU1H0OItgi3y"
      },
      "source": [
        "# Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzBxk-e_gigT"
      },
      "source": [
        "# Decoder 裡頭會有 N 個 DecoderLayer，\n",
        "# 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA & FFN\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    # 3 個 sub-layers 的主角們\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    # 定義每個 sub-layer 用的 LayerNorm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    # 定義每個 sub-layer 用的 Dropout\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           combined_mask, inp_padding_mask):\n",
        "    # 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)\n",
        "    # enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)\n",
        "    # attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)\n",
        "    # attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)\n",
        "\n",
        "    # sub-layer 1: Decoder layer 自己對輸出序列做注意力。\n",
        "    # 我們同時需要 look ahead mask 以及輸出序列的 padding mask \n",
        "    # 來避免前面已生成的子詞關注到未來的子詞以及 <pad>\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, combined_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    # sub-layer 2: Decoder layer 關注 Encoder 的最後輸出\n",
        "    # 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 <pad>\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, inp_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    # sub-layer 3: FFN 部分跟 Encoder layer 完全一樣\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    # 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWUhornggqt_",
        "outputId": "a37b18c1-ae68-42e1-c37a-8673013504ba"
      },
      "source": [
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_padding_mask:\", tar_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask:\", look_ahead_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tar_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask: tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asAN1fmGgwy1"
      },
      "source": [
        "把中文（目標語言）的詞嵌入張量以及相關的遮罩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro4BgfkfgxT-",
        "outputId": "be718cab-5b4f-40f1-fecf-a91de445731a"
      },
      "source": [
        "# 超參數\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
        "\n",
        "# 來源、目標語言的序列都需要 padding mask\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "\n",
        "# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算\n",
        "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
        "    emb_tar, enc_out, False, combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_out:\", dec_out)\n",
        "assert emb_tar.shape == dec_out.shape\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_self_attn_weights.shape:\", dec_self_attn_weights.shape)\n",
        "print(\"dec_enc_attn_weights:\", dec_enc_attn_weights.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[-0.02282319 -0.01055995  0.04843744  0.00783952]\n",
            "  [-0.01079856 -0.03693919  0.04829888 -0.01448965]\n",
            "  [ 0.04000619 -0.02590526 -0.02988156 -0.01879985]\n",
            "  [ 0.00214509  0.00248455  0.02427474  0.00176178]\n",
            "  [-0.01569381 -0.03003497 -0.03855526 -0.02174056]\n",
            "  [ 0.0400285  -0.0332581  -0.0009184   0.03477527]\n",
            "  [ 0.02867664  0.01880774  0.03228236 -0.01565862]\n",
            "  [-0.02838035  0.01158942 -0.02495556 -0.02071409]\n",
            "  [-0.02838035  0.01158942 -0.02495556 -0.02071409]\n",
            "  [-0.02838035  0.01158942 -0.02495556 -0.02071409]]\n",
            "\n",
            " [[-0.02282319 -0.01055995  0.04843744  0.00783952]\n",
            "  [ 0.01627392  0.03977975 -0.00313966 -0.00550129]\n",
            "  [-0.0023957  -0.04361086 -0.02027133  0.04017763]\n",
            "  [ 0.02209036 -0.01153525  0.03878719 -0.04587317]\n",
            "  [-0.00930882 -0.01075454 -0.02002564  0.00003041]\n",
            "  [-0.02127123 -0.02358091 -0.03141426 -0.03459009]\n",
            "  [ 0.01321514 -0.00758296  0.03461019  0.0250724 ]\n",
            "  [-0.03315058 -0.03677864  0.02746859  0.02740859]\n",
            "  [ 0.0400285  -0.0332581  -0.0009184   0.03477527]\n",
            "  [ 0.02867664  0.01880774  0.03228236 -0.01565862]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.7180352   1.4323909  -1.1244874   0.4101316 ]\n",
            "  [-0.3731438   1.4403491  -1.3135681   0.24636279]\n",
            "  [ 0.42396766  1.0011508  -1.6618913   0.23677291]\n",
            "  [-1.0246521   0.63965714 -0.91809016  1.3030851 ]\n",
            "  [-0.8036809   1.462118   -1.0361613   0.37772405]\n",
            "  [-0.7380138   0.2602049  -1.0404452   1.518254  ]\n",
            "  [-0.4572801   1.7195784  -0.49469924 -0.7675989 ]\n",
            "  [-0.4572801   1.7195784  -0.49469924 -0.7675989 ]]\n",
            "\n",
            " [[-0.3841815   1.314565   -1.384842    0.45445853]\n",
            "  [-0.9826494   1.3677015  -0.93065137  0.5455992 ]\n",
            "  [ 0.84805155 -1.64579     0.04250942  0.75522894]\n",
            "  [-0.16514704  1.202444   -1.5158596   0.4785626 ]\n",
            "  [-0.11437728  1.2537354  -1.5093584   0.37000015]\n",
            "  [-1.0233918   1.2666937  -0.9336101   0.6903083 ]\n",
            "  [-0.24762936  1.2683611  -1.4614152   0.44068357]\n",
            "  [-0.31614232 -0.19741783 -1.1087236   1.6222838 ]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[-0.15468149 -1.4401052   0.23592404  1.3588626 ]\n",
            "  [ 0.18191686 -1.6053661   0.2777895   1.1456597 ]\n",
            "  [ 1.0337924  -1.1138166  -0.87854123  0.9585655 ]\n",
            "  [-0.06924228 -1.5451245   0.41686058  1.1975061 ]\n",
            "  [ 0.47666183 -1.2050942  -0.6494977   1.37793   ]\n",
            "  [ 0.5692551  -1.3557149  -0.481048    1.2675079 ]\n",
            "  [ 1.154363   -1.5695854   0.45013925 -0.03491692]\n",
            "  [-1.3528588   0.8235083  -0.55736387  1.0867143 ]\n",
            "  [-1.3528588   0.8235083  -0.55736387  1.0867143 ]\n",
            "  [-1.3528588   0.8235083  -0.55736387  1.0867143 ]]\n",
            "\n",
            " [[-0.13779014 -1.4576614   0.25758594  1.3378656 ]\n",
            "  [ 0.40474126  1.0368556  -1.6487025   0.20710556]\n",
            "  [ 0.35108683 -1.1377896  -0.67265034  1.4593532 ]\n",
            "  [ 1.2036539  -1.5574309   0.35443383 -0.00065676]\n",
            "  [ 0.15395069 -0.83469176 -0.89410937  1.5748506 ]\n",
            "  [ 1.600109   -0.93576324 -0.746491    0.08214529]\n",
            "  [ 0.1485244  -1.577742    0.23121579  1.1980016 ]\n",
            "  [-0.28229162 -1.3571655   0.21371672  1.4257404 ]\n",
            "  [ 0.8149925  -1.3818109  -0.51212263  1.0789412 ]\n",
            "  [ 1.5322697  -1.155893    0.161975   -0.5383519 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "dec_self_attn_weights.shape: (2, 2, 10, 10)\n",
            "dec_enc_attn_weights: (2, 2, 10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6RQsa1Xg7bw"
      },
      "source": [
        "# Positional encoding：神奇數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt0QnaXmg85h",
        "outputId": "0af4a880-ba39-4168-f20d-0b94f2245ce3"
      },
      "source": [
        "# 以下直接參考 TensorFlow 官方 tutorial \n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "  \n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "  \n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "d_model = 512\n",
        "\n",
        "pos_encoding = positional_encoding(seq_len, d_model)\n",
        "pos_encoding"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
              "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        ...,\n",
              "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
              "          0.99998724,  0.99998814],\n",
              "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
              "          0.9999867 ,  0.9999876 ],\n",
              "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
              "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OLMeuDndhCJ5",
        "outputId": "fa5c2aa1-7fe2-41a7-8eef-2c4e72fe8083"
      },
      "source": [
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('d_model')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBgWwJ3-hP6N"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3dgAuAVhSlv"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：\n",
        "  # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`\n",
        "  # - input_vocab_size: 用來把索引轉成詞嵌入向量\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "    \n",
        "    # 建立 `num_layers` 個 EncoderLayers\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "    # 輸入的 x.shape == (batch_size, input_seq_len)\n",
        "    # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)\n",
        "    input_seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)\n",
        "    # 再加上對應長度的位置編碼\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :input_seq_len, :]\n",
        "\n",
        "    # 對 embedding 跟位置編碼的總合做 regularization\n",
        "    # 這在 Decoder 也會做\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    # 通過 N 個 EncoderLayer 做編碼\n",
        "    for i, enc_layer in enumerate(self.enc_layers):\n",
        "      x = enc_layer(x, training, mask)\n",
        "      # 以下只是用來 demo EncoderLayer outputs\n",
        "      #print('-' * 20)\n",
        "      #print(f\"EncoderLayer {i + 1}'s output:\", x)\n",
        "      \n",
        "    \n",
        "    return x "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvETaQp0iXDQ",
        "outputId": "1a6ddaee-0b25-4c0b-fdad-048c50f54f8f"
      },
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Encoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 初始化一個 Encoder\n",
        "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列丟入 Encoder 做編碼\n",
        "enc_out = encoder(inp, training=False, mask=None)\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.7849332  -0.59196836 -0.33270502  1.7096066 ]\n",
            "  [-0.5070656  -0.5110134  -0.708232    1.7263108 ]\n",
            "  [-0.39270163 -0.03102632 -1.1583622   1.58209   ]\n",
            "  [-0.5561628   0.3805028  -1.2407898   1.4164499 ]\n",
            "  [-0.9043199   0.1938105  -0.84728885  1.5577983 ]\n",
            "  [-0.9732156  -0.22992775 -0.46524623  1.6683894 ]\n",
            "  [-0.84681964 -0.54344726 -0.31013626  1.7004032 ]\n",
            "  [-0.6243278  -0.56790483 -0.5390009   1.7312335 ]]\n",
            "\n",
            " [[-0.77423763 -0.6076473  -0.3280061   1.7098908 ]\n",
            "  [-0.47978234 -0.56156075 -0.6860291   1.727372  ]\n",
            "  [-0.30068332 -0.07366967 -1.1973958   1.5717487 ]\n",
            "  [-0.5147843   0.2787247  -1.229085    1.4651445 ]\n",
            "  [-0.89634484  0.26754576 -0.8954111   1.5242101 ]\n",
            "  [-0.97553635 -0.22618678 -0.46569663  1.6674198 ]\n",
            "  [-0.8760045  -0.54483986 -0.27099538  1.6918397 ]\n",
            "  [-0.60130465 -0.5993665  -0.53067714  1.7313485 ]]], shape=(2, 8, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9KmTsvLiekt"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQBf2lQqiflw"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  # 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    # 為中文（目標語言）建立詞嵌入層\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "  \n",
        "  # 呼叫時的參數跟 DecoderLayer 一模一樣\n",
        "  def call(self, x, enc_output, training, \n",
        "           combined_mask, inp_padding_mask):\n",
        "    \n",
        "    tar_seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}  # 用來存放每個 Decoder layer 的注意權重\n",
        "    \n",
        "    # 這邊跟 Encoder 做的事情完全一樣\n",
        "    x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :tar_seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    \n",
        "    for i, dec_layer in enumerate(self.dec_layers):\n",
        "      x, block1, block2 = dec_layer(x, enc_output, training,\n",
        "                                    combined_mask, inp_padding_mask)\n",
        "      \n",
        "      # 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察\n",
        "      attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, tar_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKl6RVLEitwJ",
        "outputId": "ed17e5e5-1c5c-4fe2-e913-2347f178aea2"
      },
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Decoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 遮罩\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化一個 Decoder\n",
        "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列以及遮罩丟入 Decoder\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_padding_mask:\", inp_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "dec_out, attn = decoder(tar, enc_out, training=False, \n",
        "                        combined_mask=combined_mask,\n",
        "                        inp_padding_mask=inp_padding_mask)\n",
        "print(\"dec_out:\", dec_out)\n",
        "print(\"-\" * 20)\n",
        "for block_name, attn_weights in attn.items():\n",
        "  print(f\"{block_name}.shape: {attn_weights.shape}\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "combined_mask: tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)\n",
            "--------------------\n",
            "enc_out: tf.Tensor(\n",
            "[[[-0.7849332  -0.59196836 -0.33270502  1.7096066 ]\n",
            "  [-0.5070656  -0.5110134  -0.708232    1.7263108 ]\n",
            "  [-0.39270163 -0.03102632 -1.1583622   1.58209   ]\n",
            "  [-0.5561628   0.3805028  -1.2407898   1.4164499 ]\n",
            "  [-0.9043199   0.1938105  -0.84728885  1.5577983 ]\n",
            "  [-0.9732156  -0.22992775 -0.46524623  1.6683894 ]\n",
            "  [-0.84681964 -0.54344726 -0.31013626  1.7004032 ]\n",
            "  [-0.6243278  -0.56790483 -0.5390009   1.7312335 ]]\n",
            "\n",
            " [[-0.77423763 -0.6076473  -0.3280061   1.7098908 ]\n",
            "  [-0.47978234 -0.56156075 -0.6860291   1.727372  ]\n",
            "  [-0.30068332 -0.07366967 -1.1973958   1.5717487 ]\n",
            "  [-0.5147843   0.2787247  -1.229085    1.4651445 ]\n",
            "  [-0.89634484  0.26754576 -0.8954111   1.5242101 ]\n",
            "  [-0.97553635 -0.22618678 -0.46569663  1.6674198 ]\n",
            "  [-0.8760045  -0.54483986 -0.27099538  1.6918397 ]\n",
            "  [-0.60130465 -0.5993665  -0.53067714  1.7313485 ]]], shape=(2, 8, 4), dtype=float32)\n",
            "--------------------\n",
            "inp_padding_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n",
            "--------------------\n",
            "dec_out: tf.Tensor(\n",
            "[[[-1.4710399  -0.09336232  1.3315849   0.23281732]\n",
            "  [-1.5518811  -0.20778702  0.8914777   0.8681904 ]\n",
            "  [-1.4032612  -0.22656156  0.24422547  1.3855972 ]\n",
            "  [-1.3970022  -0.13661987  0.11346636  1.4201558 ]\n",
            "  [-1.5881845  -0.039864    0.539428    1.0886204 ]\n",
            "  [-1.6182089  -0.03276633  0.9189316   0.7320435 ]\n",
            "  [-1.5855601  -0.09119602  1.0280145   0.6487416 ]\n",
            "  [-1.555547   -0.19572434  0.81049395  0.94077754]\n",
            "  [-1.2315458  -0.30732068 -0.00670817  1.5455748 ]\n",
            "  [-1.2671471  -0.21472292 -0.04971692  1.5315868 ]]\n",
            "\n",
            " [[-1.4970126  -0.08266662  1.2920461   0.28763336]\n",
            "  [-1.5556847  -0.19927658  0.8678162   0.88714504]\n",
            "  [-1.4313058  -0.2116692   0.29381606  1.3491589 ]\n",
            "  [-1.4506755  -0.13231653  0.23243521  1.3505569 ]\n",
            "  [-1.5801173  -0.05520683  0.53214777  1.1031764 ]\n",
            "  [-1.6223795  -0.02206288  0.90968406  0.73475826]\n",
            "  [-1.5997616  -0.04618233  1.0279856   0.6179583 ]\n",
            "  [-1.5869963  -0.12497061  0.87024856  0.84171844]\n",
            "  [-1.3835193  -0.23209013  0.20493288  1.4106766 ]\n",
            "  [-1.2691642  -0.22470623 -0.03501846  1.5288888 ]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "decoder_layer1_block1.shape: (2, 2, 10, 10)\n",
            "decoder_layer1_block2.shape: (2, 2, 10, 8)\n",
            "decoder_layer2_block1.shape: (2, 2, 10, 10)\n",
            "decoder_layer2_block2.shape: (2, 2, 10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4WPfQati2j-"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VJ7uUxhi3g7"
      },
      "source": [
        "# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型\n",
        "class Transformer(tf.keras.Model):\n",
        "  # 初始參數包含 Encoder & Decoder 都需要超參數以及中英字典數目\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, rate)\n",
        "    # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "  \n",
        "  # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
        "  # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           combined_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, combined_mask, dec_padding_mask)\n",
        "    \n",
        "    # 將 Decoder 輸出通過最後一個 linear layer\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM7rW-JkmPt4",
        "outputId": "76617580-d294-4407-fbc8-a585be5f01ca"
      },
      "source": [
        "# 超參數\n",
        "num_layers = 1\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# + 2 是為了 <start> & <end> token\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
        "output_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 重點中的重點。訓練時用前一個字來預測下一個中文字\n",
        "tar_inp = tar[:, :-1]\n",
        "tar_real = tar[:, 1:]\n",
        "\n",
        "# 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar_inp)\n",
        "look_ahead_mask = create_look_ahead_mask(tar_inp.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化我們的第一個 transformer\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
        "                          input_vocab_size, output_vocab_size)\n",
        "\n",
        "# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果\n",
        "predictions, attn_weights = transformer(inp, tar_inp, False, inp_padding_mask, \n",
        "                                        combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_inp:\", tar_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_real:\", tar_real)\n",
        "print(\"-\" * 20)\n",
        "print(\"predictions:\", predictions)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n",
            "--------------------\n",
            "tar_inp: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3]], shape=(2, 9), dtype=int64)\n",
            "--------------------\n",
            "tar_real: tf.Tensor(\n",
            "[[  10  241   86   27    3 4206    0    0    0]\n",
            " [ 165  489  398  191   14    7  560    3 4206]], shape=(2, 9), dtype=int64)\n",
            "--------------------\n",
            "predictions: tf.Tensor(\n",
            "[[[-0.06636418  0.01534437 -0.01026297 ... -0.00765067 -0.01316521\n",
            "   -0.0486107 ]\n",
            "  [-0.05517782 -0.04726118 -0.00478664 ... -0.0701075  -0.01784743\n",
            "   -0.04254168]\n",
            "  [-0.04518513 -0.04418243  0.00063513 ... -0.05220697 -0.00805603\n",
            "   -0.01898798]\n",
            "  ...\n",
            "  [-0.0576949  -0.03209896 -0.00872019 ... -0.06180546 -0.02116563\n",
            "   -0.05390083]\n",
            "  [-0.03256461 -0.06600823 -0.00285971 ... -0.08817575 -0.01903542\n",
            "   -0.03564928]\n",
            "  [-0.04001433 -0.05209294  0.00017805 ... -0.06312844 -0.01066233\n",
            "   -0.02182026]]\n",
            "\n",
            " [[-0.06558706  0.01432966 -0.01030802 ... -0.00901675 -0.01347798\n",
            "   -0.04889873]\n",
            "  [-0.0444651  -0.05682816 -0.0032906  ... -0.07798138 -0.01756691\n",
            "   -0.0372429 ]\n",
            "  [-0.04982402 -0.0387443   0.00057521 ... -0.04567146 -0.00688727\n",
            "   -0.01868984]\n",
            "  ...\n",
            "  [-0.05818987 -0.03094594 -0.00880449 ... -0.06061006 -0.02104698\n",
            "   -0.05400923]\n",
            "  [-0.03299585 -0.06594797 -0.0038907  ... -0.09079732 -0.02077533\n",
            "   -0.03964822]\n",
            "  [-0.04155712 -0.0525421  -0.00032265 ... -0.0649798  -0.0115942\n",
            "   -0.02416863]]], shape=(2, 9, 4207), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJpxrWx5mYRU"
      },
      "source": [
        "# 定義損失函數與指標"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nW-g3McmZZC",
        "outputId": "e6174c49-6ea7-485e-a454-272629195ac6"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label\n",
        "real = tf.constant([1, 1, 0], shape=(1, 3), dtype=tf.float32)\n",
        "pred = tf.constant([[0, 1], [0, 1], [0, 1]], dtype=tf.float32)\n",
        "loss_object(real, pred)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.31326166, 0.31326166, 1.3132616 ], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8nUT5xOmgaq",
        "outputId": "25341620-dff9-420e-c60d-d389bce8d704"
      },
      "source": [
        "print(\"predictions:\", predictions)\n",
        "print(\"-\" * 20)\n",
        "print(tf.reduce_sum(predictions, axis=-1))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions: tf.Tensor(\n",
            "[[[-0.06636418  0.01534437 -0.01026297 ... -0.00765067 -0.01316521\n",
            "   -0.0486107 ]\n",
            "  [-0.05517782 -0.04726118 -0.00478664 ... -0.0701075  -0.01784743\n",
            "   -0.04254168]\n",
            "  [-0.04518513 -0.04418243  0.00063513 ... -0.05220697 -0.00805603\n",
            "   -0.01898798]\n",
            "  ...\n",
            "  [-0.0576949  -0.03209896 -0.00872019 ... -0.06180546 -0.02116563\n",
            "   -0.05390083]\n",
            "  [-0.03256461 -0.06600823 -0.00285971 ... -0.08817575 -0.01903542\n",
            "   -0.03564928]\n",
            "  [-0.04001433 -0.05209294  0.00017805 ... -0.06312844 -0.01066233\n",
            "   -0.02182026]]\n",
            "\n",
            " [[-0.06558706  0.01432966 -0.01030802 ... -0.00901675 -0.01347798\n",
            "   -0.04889873]\n",
            "  [-0.0444651  -0.05682816 -0.0032906  ... -0.07798138 -0.01756691\n",
            "   -0.0372429 ]\n",
            "  [-0.04982402 -0.0387443   0.00057521 ... -0.04567146 -0.00688727\n",
            "   -0.01868984]\n",
            "  ...\n",
            "  [-0.05818987 -0.03094594 -0.00880449 ... -0.06061006 -0.02104698\n",
            "   -0.05400923]\n",
            "  [-0.03299585 -0.06594797 -0.0038907  ... -0.09079732 -0.02077533\n",
            "   -0.03964822]\n",
            "  [-0.04155712 -0.0525421  -0.00032265 ... -0.0649798  -0.0115942\n",
            "   -0.02416863]]], shape=(2, 9, 4207), dtype=float32)\n",
            "--------------------\n",
            "tf.Tensor(\n",
            "[[-0.3397593   3.5470557   4.220676    3.2510538   0.8691917   0.8517524\n",
            "   1.9996469   3.9716787   4.2911954 ]\n",
            " [-0.33235458  3.915921    4.1316943   3.183131    1.3667076   0.87901837\n",
            "   1.9439409   3.7502358   4.263053  ]], shape=(2, 9), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3hR73SNmnOu"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  # 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 \n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  # 照樣計算所有位置的 cross entropy 但不加總\n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask  # 只計算非 <pad> 位置的損失 \n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfn4gBxamqQB"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwl6K_IzmxjH"
      },
      "source": [
        "# 設置超參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWu8b1KWmylw",
        "outputId": "b1cd02a9-ac42-472a-bb95-4a899c6c65ac"
      },
      "source": [
        "num_layers = 4 \n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2\n",
        "dropout_rate = 0.1  # 預設值\n",
        "\n",
        "print(\"input_vocab_size:\", input_vocab_size)\n",
        "print(\"target_vocab_size:\", target_vocab_size)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_vocab_size: 8115\n",
            "target_vocab_size: 4207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdJfkF0Wm3e1"
      },
      "source": [
        "# 設置 Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVrklpDdm4YE"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  # 論文預設 `warmup_steps` = 4000\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "  \n",
        "# 將客製化 learning rate schdeule 丟入 Adam opt.\n",
        "# Adam opt. 的參數都跟論文相同\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4D7yi3Y3m9f_",
        "outputId": "ad77d757-d8df-46bb-b685-b717d43c18aa"
      },
      "source": [
        "d_models = [128, 256, 512]\n",
        "warmup_steps = [1000 * i for i in range(1, 4)]\n",
        "\n",
        "schedules = []\n",
        "labels = []\n",
        "colors = [\"blue\", \"red\", \"black\"]\n",
        "for d in d_models:\n",
        "  schedules += [CustomSchedule(d, s) for s in warmup_steps]\n",
        "  labels += [f\"d_model: {d}, warm: {s}\" for s in warmup_steps]\n",
        "\n",
        "for i, (schedule, label) in enumerate(zip(schedules, labels)):\n",
        "  plt.plot(schedule(tf.range(10000, dtype=tf.float32)), \n",
        "           label=label, color=colors[i // 3])\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keRXK6r9nIkz"
      },
      "source": [
        "# 實際訓練以及定時存檔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptD9Rwd8nJoo",
        "outputId": "57752c36-9a4e-490c-c272-656ac1fc6577"
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, dropout_rate)\n",
        "\n",
        "print(f\"\"\"這個 Transformer 有 {num_layers} 層 Encoder / Decoder layers\n",
        "d_model: {d_model}\n",
        "num_heads: {num_heads}\n",
        "dff: {dff}\n",
        "input_vocab_size: {input_vocab_size}\n",
        "target_vocab_size: {target_vocab_size}\n",
        "dropout_rate: {dropout_rate}\n",
        "\n",
        "\"\"\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "這個 Transformer 有 4 層 Encoder / Decoder layers\n",
            "d_model: 128\n",
            "num_heads: 8\n",
            "dff: 512\n",
            "input_vocab_size: 8115\n",
            "target_vocab_size: 4207\n",
            "dropout_rate: 0.1\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbI-7wEMnQDo",
        "outputId": "feca49dc-d77e-4d30-d571-789d293b4148"
      },
      "source": [
        "train_perc = 20\n",
        "val_prec = 1\n",
        "drop_prec = 100 - train_perc - val_prec\n",
        "\n",
        "# 方便比較不同實驗/ 不同超參數設定的結果\n",
        "run_id = f\"{num_layers}layers_{d_model}d_{num_heads}heads_{dff}dff_{train_perc}train_perc\"\n",
        "checkpoint_path = os.path.join(checkpoint_path, run_id)\n",
        "log_dir = os.path.join(log_dir, run_id)\n",
        "\n",
        "# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取\n",
        "# 一般來說你會想存下模型以及 optimizer 的狀態\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西\n",
        "# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# 如果在 checkpoint 路徑上有發現檔案就讀進來\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  \n",
        "  # 用來確認之前訓練多少 epochs 了\n",
        "  last_epoch = int(ckpt_manager.latest_checkpoint.split(\"-\")[-1])\n",
        "  print(f'已讀取最新的 checkpoint，模型已訓練 {last_epoch} epochs。')\n",
        "else:\n",
        "  last_epoch = 0\n",
        "  print(\"沒找到 checkpoint，從頭訓練。\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "沒找到 checkpoint，從頭訓練。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUVz44uFnZIS"
      },
      "source": [
        "## 產生所有的遮罩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBgIYm4anask"
      },
      "source": [
        "# 為 Transformer 的 Encoder / Decoder 準備遮罩\n",
        "def create_masks(inp, tar):\n",
        "  # 英文句子的 padding mask，要交給 Encoder layer 自注意力機制用的\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # 同樣也是英文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2 \n",
        "  # 關注 Encoder 輸出序列用的\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Decoder layer 的 MHA1 在做自注意力機制用的\n",
        "  # `combined_mask` 是中文句子的 padding mask 跟 look ahead mask 的疊加\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzUvVmG8nlrB"
      },
      "source": [
        "# 定義 Transformer 在一次訓練步驟"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCsl1v39nqwz"
      },
      "source": [
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算\n",
        "def train_step(inp, tar):\n",
        "  # 前面說過的，用去尾的原始序列去預測下一個字的序列\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  # 建立 3 個遮罩\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降\n",
        "  with tf.GradientTape() as tape:\n",
        "    # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMv7EEKtny5I",
        "outputId": "d250a8f3-88dd-44d9-f425-5598ce74d379"
      },
      "source": [
        "# 定義我們要看幾遍數據集\n",
        "EPOCHS = 30\n",
        "print(f\"此超參數組合的 Transformer 已經訓練 {last_epoch} epochs。\")\n",
        "print(f\"剩餘 epochs：{min(0, last_epoch - EPOCHS)}\")\n",
        "\n",
        "\n",
        "# 用來寫資訊到 TensorBoard，非必要但十分推薦\n",
        "summary_writer = tf.summary.create_file_writer(log_dir)\n",
        "\n",
        "# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs\n",
        "for epoch in range(last_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  # 重置紀錄 TensorBoard 的 metrics\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 \n",
        "  for (step_idx, (inp, tar)) in enumerate(train_dataset):\n",
        "    \n",
        "    # 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss\n",
        "    train_step(inp, tar)  \n",
        "\n",
        "  # 每個 epoch 完成就存一次檔    \n",
        "  if (epoch + 1) % 1 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  # 將 loss 以及 accuracy 寫到 TensorBoard 上\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar(\"train_loss\", train_loss.result(), step=epoch + 1)\n",
        "    tf.summary.scalar(\"train_acc\", train_accuracy.result(), step=epoch + 1)\n",
        "  \n",
        "  print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "  print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "此超參數組合的 Transformer 已經訓練 0 epochs。\n",
            "剩餘 epochs：-30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i64erJBKz4h-"
      },
      "source": [
        "# 實際進行英翻中"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_Va-Q1z5gT"
      },
      "source": [
        "# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict\n",
        "def evaluate(inp_sentence):\n",
        "  \n",
        "  # 準備英文句子前後會加上的 <start>, <end>\n",
        "  start_token = [subword_encoder_en.vocab_size]\n",
        "  end_token = [subword_encoder_en.vocab_size + 1]\n",
        "  \n",
        "  # inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列\n",
        "  # 並在前後加上 BOS / EOS\n",
        "  inp_sentence = start_token + subword_encoder_en.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入\n",
        "  # 是一個只包含一個中文 <start> token 的序列\n",
        "  decoder_input = [subword_encoder_zh.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)  # 增加 batch 維度\n",
        "  \n",
        "  # auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 每多一個生成的字就得產生新的遮罩\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "\n",
        "    # 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字\n",
        "    predictions = predictions[: , -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # 遇到 <end> token 就停止回傳，代表模型已經產生完結果\n",
        "    if tf.equal(predicted_id, subword_encoder_zh.vocab_size + 1):\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    #將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生\n",
        "    # 下個中文字的時候關注到最新的 `predicted_id`\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  # 將 batch 的維度去掉後回傳預測的中文索引序列\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNl-Gx6G0K7L"
      },
      "source": [
        "## Final Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY-1Cj820NKS"
      },
      "source": [
        "# 要被翻譯的英文句子\n",
        "sentence = \"China, India, and others have enjoyed continuing economic growth.\"\n",
        "\n",
        "# 取得預測的中文索引序列\n",
        "predicted_seq, _ = evaluate(sentence)\n",
        "\n",
        "# 過濾掉 <start> & <end> tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子\n",
        "target_vocab_size = subword_encoder_zh.vocab_size\n",
        "predicted_seq_without_bos_eos = [idx for idx in predicted_seq if idx < target_vocab_size]\n",
        "predicted_sentence = subword_encoder_zh.decode(predicted_seq_without_bos_eos)\n",
        "\n",
        "print(\"sentence:\", sentence)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_seq:\", predicted_seq)\n",
        "print(\"-\" * 20)\n",
        "print(\"predicted_sentence:\", predicted_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}